{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identifier\n",
    "All datasets are from the Kaggle dog-breed-identification challenge, courtesy Stanford. \n",
    "\n",
    "This notebook covers the logic behind training the model that powers this app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D, BatchNormalization, Dense\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "target_size = 229\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to Data & Batches\n",
    "\n",
    "Training data split into individual directories in order to use Keras' flow_from_directory method.\n",
    "Roughly 10% of the Kaggle data was used for the validation set. I could have set this split percentage dynamically but after running a multitude of iterations with different split percentages, I settled on 10% (more on this when I have my own hardware)\n",
    "\n",
    "See structure.py and split_data.py to see how I went about organizing the data for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9254 images belonging to 120 classes.\n",
      "Found 968 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'data/train'\n",
    "valid_path = 'data/valid'\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./ 255,\n",
    "                               rotation_range=45,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2, zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "valid_gen = ImageDataGenerator(rescale=1./ 255)\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(train_path,\n",
    "                                              target_size=(target_size, target_size),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "valid_batches = valid_gen.flow_from_directory(valid_path,\n",
    "                                              target_size=(target_size, target_size),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception > ResNet50\n",
    "I decided to go with xception for this iteration of the app. The top_layer has not been pulled in. Feel free to use ResNet50 but make sure to change the target_size to 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(target_size, target_size, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze Layers from base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = base_model.output\n",
    "output = BatchNormalization()(output)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(1024, activation='relu')(output)\n",
    "output = Dropout(0.25)(output)\n",
    "predictions = Dense(120, activation='softmax', name='predictions')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = base_model.output\n",
    "#output = GlobalAveragePooling2D()(output)\n",
    "#output = Dropout(0.3)(output)\n",
    "#output = Dense(1024, activation='relu')(output)\n",
    "#predictions = Dense(120, activation='softmax', name='predictions')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = base_model.get_layer(index=-1).output\n",
    "model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = RMSprop(lr=0.001, rho=0.9)\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "#optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#optimizer = 'rmsprop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "289/289 [==============================] - 116s 401ms/step - loss: 2.7443 - acc: 0.3680 - val_loss: 1.1399 - val_acc: 0.7427\n",
      "Epoch 2/50\n",
      "289/289 [==============================] - 115s 397ms/step - loss: 1.8304 - acc: 0.5304 - val_loss: 1.0897 - val_acc: 0.7618\n",
      "Epoch 3/50\n",
      "289/289 [==============================] - 114s 396ms/step - loss: 1.6869 - acc: 0.5547 - val_loss: 1.1585 - val_acc: 0.7585\n",
      "Epoch 4/50\n",
      "289/289 [==============================] - 114s 396ms/step - loss: 1.6530 - acc: 0.5621 - val_loss: 1.0805 - val_acc: 0.7671\n",
      "Epoch 5/50\n",
      "289/289 [==============================] - 114s 395ms/step - loss: 1.5586 - acc: 0.5843 - val_loss: 1.0035 - val_acc: 0.7767\n",
      "Epoch 6/50\n",
      "289/289 [==============================] - 114s 395ms/step - loss: 1.4900 - acc: 0.6002 - val_loss: 1.0624 - val_acc: 0.7596\n",
      "Epoch 7/50\n",
      "289/289 [==============================] - 115s 397ms/step - loss: 1.4560 - acc: 0.6049 - val_loss: 1.1781 - val_acc: 0.7532\n",
      "Epoch 8/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.3974 - acc: 0.6196 - val_loss: 1.1365 - val_acc: 0.7703\n",
      "Epoch 9/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.3877 - acc: 0.6226 - val_loss: 0.9788 - val_acc: 0.7724\n",
      "Epoch 10/50\n",
      "289/289 [==============================] - 114s 395ms/step - loss: 1.3330 - acc: 0.6282 - val_loss: 1.1439 - val_acc: 0.7543\n",
      "Epoch 11/50\n",
      "289/289 [==============================] - 115s 396ms/step - loss: 1.3052 - acc: 0.6409 - val_loss: 1.0963 - val_acc: 0.7682\n",
      "Epoch 12/50\n",
      "289/289 [==============================] - 114s 395ms/step - loss: 1.2692 - acc: 0.6443 - val_loss: 1.0895 - val_acc: 0.7639\n",
      "Epoch 13/50\n",
      "289/289 [==============================] - 114s 395ms/step - loss: 1.2692 - acc: 0.6436 - val_loss: 1.0332 - val_acc: 0.7821\n",
      "Epoch 14/50\n",
      "289/289 [==============================] - 113s 393ms/step - loss: 1.2578 - acc: 0.6519 - val_loss: 1.0945 - val_acc: 0.7585\n",
      "Epoch 15/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.1924 - acc: 0.6658 - val_loss: 1.2307 - val_acc: 0.7468\n",
      "Epoch 16/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 1.1811 - acc: 0.6653 - val_loss: 1.0751 - val_acc: 0.7703\n",
      "Epoch 17/50\n",
      "289/289 [==============================] - 114s 395ms/step - loss: 1.1484 - acc: 0.6716 - val_loss: 1.2521 - val_acc: 0.7489\n",
      "Epoch 18/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.1550 - acc: 0.6769 - val_loss: 1.1389 - val_acc: 0.7628\n",
      "Epoch 19/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.1147 - acc: 0.6825 - val_loss: 1.2829 - val_acc: 0.7532\n",
      "Epoch 20/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.1103 - acc: 0.6910 - val_loss: 1.1291 - val_acc: 0.7553\n",
      "Epoch 21/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 1.1126 - acc: 0.6857 - val_loss: 1.2681 - val_acc: 0.7596\n",
      "Epoch 22/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.0905 - acc: 0.6882 - val_loss: 1.1888 - val_acc: 0.7618\n",
      "Epoch 23/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 1.0867 - acc: 0.6911 - val_loss: 1.2455 - val_acc: 0.7543\n",
      "Epoch 24/50\n",
      "289/289 [==============================] - 113s 391ms/step - loss: 1.0515 - acc: 0.7045 - val_loss: 1.1116 - val_acc: 0.7682\n",
      "Epoch 25/50\n",
      "289/289 [==============================] - 114s 394ms/step - loss: 1.0660 - acc: 0.6931 - val_loss: 1.2441 - val_acc: 0.7543\n",
      "Epoch 26/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 1.0143 - acc: 0.7108 - val_loss: 1.2756 - val_acc: 0.7585\n",
      "Epoch 27/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 1.0100 - acc: 0.7076 - val_loss: 1.2172 - val_acc: 0.7564\n",
      "Epoch 28/50\n",
      "289/289 [==============================] - 113s 391ms/step - loss: 0.9985 - acc: 0.7089 - val_loss: 1.2637 - val_acc: 0.7479\n",
      "Epoch 29/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 1.0015 - acc: 0.7147 - val_loss: 1.2652 - val_acc: 0.7468\n",
      "Epoch 30/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 0.9942 - acc: 0.7173 - val_loss: 1.3290 - val_acc: 0.7607\n",
      "Epoch 31/50\n",
      "289/289 [==============================] - 113s 393ms/step - loss: 0.9557 - acc: 0.7275 - val_loss: 1.1625 - val_acc: 0.7692\n",
      "Epoch 32/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 0.9711 - acc: 0.7252 - val_loss: 1.2708 - val_acc: 0.7573\n",
      "Epoch 33/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 0.9842 - acc: 0.7172 - val_loss: 1.3205 - val_acc: 0.7468\n",
      "Epoch 34/50\n",
      "289/289 [==============================] - 113s 391ms/step - loss: 0.9187 - acc: 0.7359 - val_loss: 1.2907 - val_acc: 0.7500\n",
      "Epoch 35/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 0.9595 - acc: 0.7219 - val_loss: 1.2786 - val_acc: 0.7564\n",
      "Epoch 36/50\n",
      "289/289 [==============================] - 113s 390ms/step - loss: 0.9369 - acc: 0.7269 - val_loss: 1.2715 - val_acc: 0.7564\n",
      "Epoch 37/50\n",
      "289/289 [==============================] - 113s 391ms/step - loss: 0.9399 - acc: 0.7335 - val_loss: 1.3147 - val_acc: 0.7532\n",
      "Epoch 38/50\n",
      "289/289 [==============================] - 113s 391ms/step - loss: 0.9204 - acc: 0.7288 - val_loss: 1.1808 - val_acc: 0.7842\n",
      "Epoch 39/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 0.9085 - acc: 0.7340 - val_loss: 1.4518 - val_acc: 0.7393\n",
      "Epoch 40/50\n",
      "289/289 [==============================] - 113s 391ms/step - loss: 0.8900 - acc: 0.7404 - val_loss: 1.2276 - val_acc: 0.7521\n",
      "Epoch 41/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 0.8876 - acc: 0.7410 - val_loss: 1.4171 - val_acc: 0.7457\n",
      "Epoch 42/50\n",
      "289/289 [==============================] - 113s 392ms/step - loss: 0.8884 - acc: 0.7415 - val_loss: 1.3384 - val_acc: 0.7596\n",
      "Epoch 43/50\n",
      "289/289 [==============================] - 113s 390ms/step - loss: 0.8721 - acc: 0.7466 - val_loss: 1.3151 - val_acc: 0.7468\n",
      "Epoch 44/50\n",
      "289/289 [==============================] - 114s 393ms/step - loss: 0.8614 - acc: 0.7460 - val_loss: 1.4086 - val_acc: 0.7585\n",
      "Epoch 45/50\n",
      "289/289 [==============================] - 113s 390ms/step - loss: 0.8422 - acc: 0.7549 - val_loss: 1.2977 - val_acc: 0.7842\n",
      "Epoch 46/50\n",
      "289/289 [==============================] - 112s 389ms/step - loss: 0.8609 - acc: 0.7477 - val_loss: 1.5200 - val_acc: 0.7564\n",
      "Epoch 47/50\n",
      "289/289 [==============================] - 113s 390ms/step - loss: 0.8470 - acc: 0.7548 - val_loss: 1.2841 - val_acc: 0.7639\n",
      "Epoch 48/50\n",
      "289/289 [==============================] - 113s 390ms/step - loss: 0.8537 - acc: 0.7580 - val_loss: 1.3767 - val_acc: 0.7628\n",
      "Epoch 49/50\n",
      "289/289 [==============================] - 112s 389ms/step - loss: 0.8306 - acc: 0.7624 - val_loss: 1.5123 - val_acc: 0.7436\n",
      "Epoch 50/50\n",
      "288/289 [============================>.] - ETA: 0s - loss: 0.8500 - acc: 0.7524"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=train_batches.n // batch_size, validation_data=valid_batches, validation_steps=valid_batches.n // batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
