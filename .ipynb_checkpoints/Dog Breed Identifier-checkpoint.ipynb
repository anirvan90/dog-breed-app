{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identifier\n",
    "All datasets are from the Kaggle dog-breed-identification challenge, courtesy Stanford. \n",
    "\n",
    "This notebook covers the logic behind training the model that powers this app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D, BatchNormalization, Dense\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "target_size = 229\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to Data & Batches\n",
    "\n",
    "Training data split into individual directories in order to use Keras' flow_from_directory method.\n",
    "Roughly 10% of the Kaggle data was used for the validation set. I could have set this split percentage dynamically but after running a multitude of iterations with different split percentages, I settled on 10% (more on this when I have my own hardware)\n",
    "\n",
    "See structure.py and split_data.py to see how I went about organizing the data for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train'\n",
    "valid_path = 'data/valid'\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./ 255,\n",
    "                               rotation_range=45,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2, zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "valid_gen = ImageDataGenerator(rescale=1./ 255)\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(train_path,\n",
    "                                              target_size=(target_size, target_size),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "valid_batches = valid_gen.flow_from_directory(valid_path,\n",
    "                                              target_size=(target_size, target_size),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception > ResNet50\n",
    "I decided to go with xception for this iteration of the app. The top_layer has not been pulled in. Feel free to use ResNet50 but make sure to change the target_size to 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(target_size, target_size, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze Layers from base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = base_model.output\n",
    "output = BatchNormalization()(output)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(1024, activation='relu')(output)\n",
    "output = Dropout(0.25)(output)\n",
    "predictions = Dense(120, activation='softmax', name='predictions')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = base_model.output\n",
    "#output = GlobalAveragePooling2D()(output)\n",
    "#output = Dropout(0.3)(output)\n",
    "#output = Dense(1024, activation='relu')(output)\n",
    "#predictions = Dense(120, activation='softmax', name='predictions')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = base_model.get_layer(index=-1).output\n",
    "model = Model(base_model.input,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = RMSprop(lr=0.001, rho=0.9)\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "#optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#optimizer = 'rmsprop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=train_batches.n // batch_size, validation_data=valid_batches, validation_steps=valid_batches.n // batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
